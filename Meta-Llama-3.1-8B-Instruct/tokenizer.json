{
	"tokenizer_name": "Meta-Llama-Tokenizer",
	"language": "English",
	"version": "1.0",
	"special_tokens": {
	  "start_token": "<START>",
	  "end_token": "<END>",
	  "pad_token": "<PAD>",
	  "unknown_token": "<UNK>"
	}
  }